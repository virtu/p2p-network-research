{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read annotated nodes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "ANNOTATED_NODES_CSV = \"reachable-nodes-annotated-2023-05-07.csv\"\n",
    "\n",
    "assert os.path.exists(ANNOTATED_NODES_CSV), \"Annotated node data missing! Run 01_prep_input_data.ipynb to create.\"\n",
    "\n",
    "df = pd.read_csv(ANNOTATED_NODES_CSV)\n",
    "\n",
    "# address statistics\n",
    "num_ipv4 = sum(df.network == 'ipv4')\n",
    "num_ipv6 = sum(df.network == 'ipv6')\n",
    "num_ip = len(df)\n",
    "assert num_ipv4 + num_ipv6 == num_ip, \"Inconsistent dichotomy\"\n",
    "print(f'reachable nodes: ipv4={num_ipv4}, ipv6={num_ipv6}, ipv4/ipv6={num_ip}')\n",
    "\n",
    "# netgroup statistics\n",
    "ip_netgroups = df.netgroup.value_counts().values\n",
    "ipv4_netgroups = df[df.network == 'ipv4'].netgroup.value_counts().values\n",
    "ipv6_netgroups = df[df.network == 'ipv6'].netgroup.value_counts().values\n",
    "assert sum(ipv4_netgroups) + sum(ipv6_netgroups) + sum(ip_netgroups) == 2 * len(df), \"Inconsistent dichotomy!\"\n",
    "print(f'netgroups: ipv4={len(ipv4_netgroups)}, ipv6={len(ipv6_netgroups)}, ipv4/ipv6={len(ip_netgroups)}, total_addresses={sum(ip_netgroups)}')\n",
    "\n",
    "# asn statistics\n",
    "ip_asns = df.asn.value_counts().values\n",
    "ipv4_asns = df[df.network == 'ipv4'].asn.value_counts().values\n",
    "ipv6_asns = df[df.network == 'ipv6'].asn.value_counts().values\n",
    "assert sum(ipv4_asns) + sum(ipv6_asns) + sum(ip_asns) == 2 * len(df), \"Inconsistent dichotomy!\"\n",
    "print(f'asn: ipv4={len(ipv4_asns)}, ipv6={len(ipv6_asns)}, ipv4/ipv6={len(ip_asns)}, total_addresses={sum(ip_asns)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of analytic model with Monte Carlo\n",
    "\n",
    "- Speed-accuracy tradeoff can be tuned with `MONTECARLO_ITERATIONS`\n",
    "- Comparison carried out with data from netgroup policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# BiasedUrn R package\n",
    "import rpy2.robjects.packages as rpackages\n",
    "from rpy2.robjects.vectors import IntVector, FloatVector\n",
    "import rpy2.robjects as robjects\n",
    "biasedurn = rpackages.importr('BiasedUrn')\n",
    "\n",
    "def p_eclipse_montecarlo(good_bucket_sizes: list[int], bad_bucket_size: float, num_bad_buckets: int, num_outbound_conns: int = 10) -> float:\n",
    "    \"\"\"\n",
    "    Compute eclipse probability (i.e. all outbound to attacker nodes) using a\n",
    "    Monte Carlo simulation. Cache results to avoid redundant lengthy computations.\n",
    "    \"\"\"\n",
    "    bad_bucket_sizes = tuple([bad_bucket_size]) * num_bad_buckets\n",
    "    bucket_sizes = np.array(good_bucket_sizes + bad_bucket_sizes)\n",
    "    a = np.arange(len(bucket_sizes))        # population from which samples are drawn\n",
    "    size = num_outbound_conns               # number of samples\n",
    "    replace = False                         # sample without replacements\n",
    "    p = bucket_sizes/bucket_sizes.sum()     # probabilities associated with entries in a\n",
    "\n",
    "    count = 0\n",
    "    for _ in range(MONTECARLO_ITERATIONS):\n",
    "        draw = np.random.choice(a, size, replace, p=bucket_sizes/bucket_sizes.sum())\n",
    "        if np.sum(draw >= len(good_bucket_sizes)) == num_outbound_conns:\n",
    "            count += 1\n",
    "\n",
    "    p = count / MONTECARLO_ITERATIONS\n",
    "    return p\n",
    "\n",
    "def p_eclipse_wallenius(good_bucket_sizes: tuple[int], bad_bucket_size: float, num_bad_buckets: int, num_outbound_conns: int = 10) -> float:\n",
    "    x = IntVector([0] * len(good_bucket_sizes) + [num_outbound_conns])  # number of balls of each color sampled: zero benign balls, number of outgoing conns. bad balls\n",
    "    m = IntVector([1] * len(good_bucket_sizes) + [num_bad_buckets])     # initial number of balls of each color: one ball for each benign color, number of buckets balls for bad color\n",
    "    n = num_outbound_conns                                              # number of balls sampled: number of outbound connections\n",
    "    odds = FloatVector(good_bucket_sizes + tuple([bad_bucket_size]))    # weight for each color, arbitrarily scaled: number of nodes in bucket\n",
    "    p = biasedurn.dMWNCHypergeo(x=x, m=m, n=n, odds=odds)               # returns an R FloatVector that contains one element\n",
    "    return p[0]\n",
    "\n",
    "\n",
    "# define parameters\n",
    "MONTECARLO_ITERATIONS = 50000 # 50000 was used for the chart in the article\n",
    "good_netgroup_sizes = [ipv4_netgroups]\n",
    "num_bad_nodes = [20000, 30000]\n",
    "netgroup_ratio = np.logspace(np.log10(0.001), np.log10(0.3), num=40, base=10)\n",
    "df_netgroup = pd.DataFrame(list(product(good_netgroup_sizes, num_bad_nodes, netgroup_ratio)), columns=['good_netgroup_sizes', 'num_bad_nodes', 'netgroup_ratio'])\n",
    "df_netgroup['num_bad_netgroups'] = (df_netgroup.num_bad_nodes * df_netgroup.netgroup_ratio).astype(int)\n",
    "df_netgroup['bad_netgroup_size'] = df_netgroup.num_bad_nodes / df_netgroup.num_bad_netgroups\n",
    "\n",
    "# run parameter studies\n",
    "df_netgroup['p_montecarlo'] = df_netgroup.progress_apply(lambda x: p_eclipse_montecarlo(tuple(x.good_netgroup_sizes), x.bad_netgroup_size, x.num_bad_netgroups), axis=1)\n",
    "df_netgroup['p_wallenius'] = df_netgroup.apply(lambda x: p_eclipse_wallenius(tuple(x.good_netgroup_sizes), x.bad_netgroup_size, x.num_bad_netgroups), axis=1)\n",
    "\n",
    "# plot (analytic results use lines; mc validation uses x marker)\n",
    "_ = sns.lineplot(data=df_netgroup, x='num_bad_netgroups', y='p_wallenius', hue='num_bad_nodes', legend=False)\n",
    "g = sns.scatterplot(data=df_netgroup, x='num_bad_netgroups', y='p_montecarlo', hue='num_bad_nodes', marker='x')\n",
    "g.set_xscale('log')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate distribution-independence of eclipse probabilities\n",
    "\n",
    "- Demonstrate `p_eclipse` is identical for netgroup and ASN bucketing (i.e., independent of the distribution of benign nodes across buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "num_bad_nodes = range(10000, 50000, 5000)\n",
    "num_bad_buckets = range(10, 200, 10)\n",
    "\n",
    "df_in = pd.DataFrame(list(product(num_bad_nodes, num_bad_buckets)), columns=['num_bad_nodes', 'num_bad_buckets'])\n",
    "df_in['bad_bucket_size'] = df_in.num_bad_nodes / df_in.num_bad_buckets\n",
    "df_in['good_netgroup_sizes'] = [tuple(ip_netgroups)] * len(df_in)\n",
    "df_in['good_asn_sizes'] = [tuple(ip_asns)] * len(df_in)\n",
    "\n",
    "# run parameter studies\n",
    "df_in['p_netgroup'] = df_in.progress_apply(lambda x: p_eclipse_wallenius(tuple(x.good_netgroup_sizes), x.bad_bucket_size, x.num_bad_buckets), axis=1)\n",
    "df_in['p_asn'] = df_in.progress_apply(lambda x: p_eclipse_wallenius(tuple(x.good_asn_sizes), x.bad_bucket_size, x.num_bad_buckets), axis=1)\n",
    "\n",
    "\n",
    "# plot (analytic results use lines; mc validation uses x marker)\n",
    "_ = sns.lineplot(data=df_in, x='num_bad_buckets', y='p_netgroup', hue='num_bad_nodes', legend=False)\n",
    "g = sns.scatterplot(data=df_in, x='num_bad_buckets', y='p_asn', hue='num_bad_nodes', marker='x')\n",
    "g.set_ylabel('Number of attacker buckets')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate validity of transformations of distribution of benign nodes\n",
    "\n",
    "- Map all benign nodes into a single bucket before calling function that computes Wallenius function and compare to vanilla results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_eclipse_wallenius_fast(good_bucket_sizes: tuple[int], bad_bucket_size: float, num_bad_buckets: int, num_outbound_conns: int = 10) -> float:\n",
    "    x = IntVector([0] + [num_outbound_conns])  # number of balls of each color sampled: zero benign balls, number of outgoing conns. bad balls\n",
    "    m = IntVector([1] + [num_bad_buckets])     # initial number of balls of each color: one ball for each benign color, number of buckets balls for bad color\n",
    "    n = num_outbound_conns                     # number of balls sampled: number of outbound connections\n",
    "    odds = FloatVector(tuple([sum(good_bucket_sizes)]) + tuple([bad_bucket_size]))  # weight for each color, arbitrarily scaled: number of nodes in bucket\n",
    "    p = biasedurn.dMWNCHypergeo(x=x, m=m, n=n, odds=odds)   # returns an R FloatVector that contains one element\n",
    "    return p[0]\n",
    "\n",
    "good_netgroup_sizes = [ipv4_netgroups]\n",
    "num_bad_nodes = [20000, 30000]\n",
    "netgroup_ratio = np.logspace(np.log10(0.001), np.log10(0.3), num=40, base=10)\n",
    "df_in = pd.DataFrame(list(product(good_netgroup_sizes, num_bad_nodes, netgroup_ratio)), columns=['good_netgroup_sizes', 'num_bad_nodes', 'netgroup_ratio'])\n",
    "df_in['num_bad_netgroups'] = (df_in.num_bad_nodes * df_in.netgroup_ratio).astype(int)\n",
    "df_in['bad_netgroup_size'] = df_in.num_bad_nodes / df_in.num_bad_netgroups\n",
    "\n",
    "# run parameter studies\n",
    "df_in['p_wallenius_fast'] = df_in.progress_apply(lambda x: p_eclipse_wallenius_fast(tuple(x.good_netgroup_sizes), x.bad_netgroup_size, x.num_bad_netgroups), axis=1)\n",
    "df_in['p_wallenius'] = df_in.progress_apply(lambda x: p_eclipse_wallenius(tuple(x.good_netgroup_sizes), x.bad_netgroup_size, x.num_bad_netgroups), axis=1)\n",
    "\n",
    "# plot (analytic results use lines; mc validation uses x marker)\n",
    "_ = sns.lineplot(data=df_in, x='num_bad_netgroups', y='p_wallenius', hue='num_bad_nodes', legend=False)\n",
    "g = sns.scatterplot(data=df_in, x='num_bad_netgroups', y='p_wallenius_fast', hue='num_bad_nodes', marker='x')\n",
    "g.set_xscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7cb1b9ae4d417fedf7f40a8eec98f7cfbd359e096bd857395a915f4609834ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
